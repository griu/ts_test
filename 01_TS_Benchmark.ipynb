{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U mxnet-cu101mkl==1.6.0  # updating mxnet to at least v1.6\n",
    "!pip install gluonts\n",
    "# edit -> notebook setting -> Python 3 GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import np, npx\n",
    "from mxnet.gluon import nn\n",
    "npx.set_np()\n",
    "\n",
    "npx.cpu(), npx.gpu(), npx.gpu(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data, train_size, forecast_size = 3500, 2900, 600\n",
    "url = \"https://raw.githubusercontent.com/numenta/NAB/master/data/realTweets/Twitter_volume_AMZN.csv\"\n",
    "df = pd.read_csv(url, header=0, index_col=0, nrows=total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARIMA():\n",
    "    from statsmodels.tsa.arima_model import ARIMA\n",
    "    new_df_AMZ = pd.DataFrame(df['value']).reset_index().rename(columns={'timestamp': 'ds', 'value': 'y'})\n",
    "    new_df_AMZ.head()\n",
    "    X = new_df_AMZ['y'].tolist()\n",
    "    train, test = X[0:forecast_size], X[train_size:len(X)]\n",
    "    history = [x for x in train]\n",
    "    ARIMA_predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=(5, 1, 0))\n",
    "        model_fit = model.fit(disp=0)\n",
    "        output = model_fit.forecast()\n",
    "        yhat = output[0]\n",
    "        ARIMA_predictions.append(yhat)\n",
    "        obs = test[t]\n",
    "        history.append(obs)\n",
    "    error = mean_squared_error(test, ARIMA_predictions)\n",
    "    print('ARIMA MSE: %.3f' % error)\n",
    "    return ARIMA_predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GlounTS():\n",
    "    #from pts.dataset import ListDataset\n",
    "    #from pts.model.deepar import DeepAREstimator\n",
    "    #from pts import Trainer\n",
    "    #from pts.dataset import to_pandas\n",
    "    # gluonts crash in my sistem.\n",
    "    from gluonts.dataset.common import ListDataset\n",
    "    from gluonts.model.deepar import DeepAREstimator\n",
    "    from gluonts.trainer import Trainer\n",
    "    training_data = ListDataset([{\"start\": df.index[0], \"target\": df.value[:\"2015-03-08 23:22:53\"]}], freq=\"5min\")\n",
    "    #estimator = DeepAREstimator(freq=\"5min\",input_size = 43, prediction_length=forecast_size, trainer=Trainer(epochs=20))\n",
    "    estimator = DeepAREstimator(freq=\"5min\", prediction_length=forecast_size, trainer=Trainer(epochs=20))\n",
    "    predictor = estimator.train(training_data=training_data)\n",
    "    test_data = ListDataset([{\"start\": df.index[0], \"target\": df.value[:\"2015-03-08 23:22:53\"]}], freq=\"5min\")\n",
    "    GluonTS_prediction = next(predictor.predict(test_data))\n",
    "    GluonTS_mean_yhat = GluonTS_prediction.mean\n",
    "    GluonTS_median_yhat = GluonTS_prediction.median\n",
    "    return GluonTS_mean_yhat.tolist(), GluonTS_median_yhat.tolist(), GluonTS_prediction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fbprophet():\n",
    "    from fbprophet import Prophet\n",
    "    new_df_AMZ = pd.DataFrame(df['value']).reset_index().rename(columns={'timestamp': 'ds', 'value': 'y'})\n",
    "    new_df_AMZ.head()\n",
    "    new_df_AMZ['y'] = np.log(new_df_AMZ['y'])\n",
    "    model = Prophet()\n",
    "    model.fit(new_df_AMZ)\n",
    "    future = model.make_future_dataframe(periods=forecast_size)\n",
    "    forecast = model.predict(future)\n",
    "    forecast.head()\n",
    "    fb_model_close = pd.DataFrame(df['value'])\n",
    "    fb_model = forecast.set_index('ds').join(fb_model_close)\n",
    "    fb_model = fb_model[['value', 'yhat', 'yhat_upper', 'yhat_lower']].dropna().tail(forecast_size)\n",
    "    fb_model['yhat'] = np.exp(fb_model.yhat)\n",
    "    fb_model['yhat_upper'] = np.exp(fb_model.yhat_upper)\n",
    "    fb_model['yhat_lower'] = np.exp(fb_model.yhat_lower)\n",
    "    fbp_history = fb_model['value']\n",
    "    fbp_yhat = fb_model.yhat\n",
    "    fbp_yhat_upper = fb_model.yhat_upper\n",
    "    fbp_yhat_lower = fb_model.yhat_lower\n",
    "    print(\"fbprophet MSE:\", metrics.mean_squared_error(fbp_yhat, fbp_history))\n",
    "    print(\"fbprophet MAE:\", metrics.mean_absolute_error(fbp_yhat, fbp_history))\n",
    "    return fbp_history, fbp_yhat, fbp_yhat_upper, fbp_yhat_lower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"GluonTS!\")\n",
    "    GluonTS_mean_yhat, GluonTS_median_yhat, GluonTS_forecast = GlounTS()\n",
    "    print(\"Fbprophet!\")\n",
    "    fbp_history, fbp_yhat, fbp_yhat_upper, fbp_yhat_lower = Fbprophet()\n",
    "    print(\"ARIMAX!\")\n",
    "    ARIMA_predictions = ARIMA()\n",
    "    frame = {'fbp_history': fbp_history, 'fbp_yhat': fbp_yhat, \\\n",
    "             'fbp_yhat_upper': fbp_yhat_upper, 'fbp_yhat_lower': fbp_yhat_lower, \\\n",
    "             'ARIMA_predictions': (np.transpose(ARIMA_predictions).flatten().tolist()), \\\n",
    "             'GlounTS_mean_yhat': (np.transpose(GluonTS_mean_yhat).flatten().tolist()), \\\n",
    "             'GlounTS_median_yhat': (np.transpose(GluonTS_median_yhat).flatten().tolist())}\n",
    "    result = pd.DataFrame(frame)\n",
    "    result.plot(fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_env",
   "language": "python",
   "name": "ts_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
