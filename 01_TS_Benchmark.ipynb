{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gluonts mxnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data, train_size, forecast_size = 3500, 2900, 600\n",
    "url = \"https://raw.githubusercontent.com/numenta/NAB/master/data/realTweets/Twitter_volume_AMZN.csv\"\n",
    "df = pd.read_csv(url, header=0, index_col=0, nrows=total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARIMA():\n",
    "    from statsmodels.tsa.arima_model import ARIMA\n",
    "    new_df_AMZ = pd.DataFrame(df['value']).reset_index().rename(columns={'timestamp': 'ds', 'value': 'y'})\n",
    "    new_df_AMZ.head()\n",
    "    X = new_df_AMZ['y'].tolist()\n",
    "    train, test = X[0:forecast_size], X[train_size:len(X)]\n",
    "    history = [x for x in train]\n",
    "    ARIMA_predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=(5, 1, 0))\n",
    "        model_fit = model.fit(disp=0)\n",
    "        output = model_fit.forecast()\n",
    "        yhat = output[0]\n",
    "        ARIMA_predictions.append(yhat)\n",
    "        obs = test[t]\n",
    "        history.append(obs)\n",
    "    error = mean_squared_error(test, ARIMA_predictions)\n",
    "    print('ARIMA MSE: %.3f' % error)\n",
    "    return ARIMA_predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GlounTS():\n",
    "    #from pts.dataset import ListDataset\n",
    "    #from pts.model.deepar import DeepAREstimator\n",
    "    #from pts import Trainer\n",
    "    #from pts.dataset import to_pandas\n",
    "    # gluonts crash in my sistem.\n",
    "    from gluonts.dataset.common import ListDataset\n",
    "    from gluonts.model.deepar import DeepAREstimator\n",
    "    from gluonts.trainer import Trainer\n",
    "    training_data = ListDataset([{\"start\": df.index[0], \"target\": df.value[:\"2015-03-08 23:22:53\"]}], freq=\"5min\")\n",
    "    #estimator = DeepAREstimator(freq=\"5min\",input_size = 43, prediction_length=forecast_size, trainer=Trainer(epochs=20))\n",
    "    estimator = DeepAREstimator(freq=\"5min\", prediction_length=forecast_size, trainer=Trainer(epochs=20))\n",
    "    predictor = estimator.train(training_data=training_data)\n",
    "    test_data = ListDataset([{\"start\": df.index[0], \"target\": df.value[:\"2015-03-08 23:22:53\"]}], freq=\"5min\")\n",
    "    GluonTS_prediction = next(predictor.predict(test_data))\n",
    "    GluonTS_mean_yhat = GluonTS_prediction.mean\n",
    "    GluonTS_median_yhat = GluonTS_prediction.median\n",
    "    return GluonTS_mean_yhat.tolist(), GluonTS_median_yhat.tolist(), GluonTS_prediction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fbprophet():\n",
    "    from fbprophet import Prophet\n",
    "    new_df_AMZ = pd.DataFrame(df['value']).reset_index().rename(columns={'timestamp': 'ds', 'value': 'y'})\n",
    "    new_df_AMZ.head()\n",
    "    new_df_AMZ['y'] = np.log(new_df_AMZ['y'])\n",
    "    model = Prophet()\n",
    "    model.fit(new_df_AMZ)\n",
    "    future = model.make_future_dataframe(periods=forecast_size)\n",
    "    forecast = model.predict(future)\n",
    "    forecast.head()\n",
    "    fb_model_close = pd.DataFrame(df['value'])\n",
    "    fb_model = forecast.set_index('ds').join(fb_model_close)\n",
    "    fb_model = fb_model[['value', 'yhat', 'yhat_upper', 'yhat_lower']].dropna().tail(forecast_size)\n",
    "    fb_model['yhat'] = np.exp(fb_model.yhat)\n",
    "    fb_model['yhat_upper'] = np.exp(fb_model.yhat_upper)\n",
    "    fb_model['yhat_lower'] = np.exp(fb_model.yhat_lower)\n",
    "    fbp_history = fb_model['value']\n",
    "    fbp_yhat = fb_model.yhat\n",
    "    fbp_yhat_upper = fb_model.yhat_upper\n",
    "    fbp_yhat_lower = fb_model.yhat_lower\n",
    "    print(\"fbprophet MSE:\", metrics.mean_squared_error(fbp_yhat, fbp_history))\n",
    "    print(\"fbprophet MAE:\", metrics.mean_absolute_error(fbp_yhat, fbp_history))\n",
    "    return fbp_history, fbp_yhat, fbp_yhat_upper, fbp_yhat_lower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"GluonTS!\")\n",
    "    GluonTS_mean_yhat, GluonTS_median_yhat, GluonTS_forecast = GlounTS()\n",
    "    print(\"Fbprophet!\")\n",
    "    fbp_history, fbp_yhat, fbp_yhat_upper, fbp_yhat_lower = Fbprophet()\n",
    "    print(\"ARIMAX!\")\n",
    "    ARIMA_predictions = ARIMA()\n",
    "    frame = {'fbp_history': fbp_history, 'fbp_yhat': fbp_yhat, \\\n",
    "             'fbp_yhat_upper': fbp_yhat_upper, 'fbp_yhat_lower': fbp_yhat_lower, \\\n",
    "             'ARIMA_predictions': (np.transpose(ARIMA_predictions).flatten().tolist()), \\\n",
    "             'GlounTS_mean_yhat': (np.transpose(GluonTS_mean_yhat).flatten().tolist()), \\\n",
    "             'GlounTS_median_yhat': (np.transpose(GluonTS_median_yhat).flatten().tolist())}\n",
    "    result = pd.DataFrame(frame)\n",
    "    result.plot(fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GluonTS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.08s/it, epoch=1/20, avg_epoch_loss=4.51]\n",
      "100%|██████████| 50/50 [00:43<00:00,  1.16it/s, epoch=2/20, avg_epoch_loss=4.14]\n",
      "100%|██████████| 50/50 [00:42<00:00,  1.18it/s, epoch=3/20, avg_epoch_loss=4.08]\n",
      "100%|██████████| 50/50 [00:42<00:00,  1.17it/s, epoch=4/20, avg_epoch_loss=4.05]\n",
      "100%|██████████| 50/50 [00:42<00:00,  1.18it/s, epoch=5/20, avg_epoch_loss=4.02]\n",
      "100%|██████████| 50/50 [00:42<00:00,  1.18it/s, epoch=6/20, avg_epoch_loss=4.01]\n",
      "100%|██████████| 50/50 [00:42<00:00,  1.19it/s, epoch=7/20, avg_epoch_loss=3.99]\n",
      "100%|██████████| 50/50 [00:42<00:00,  1.19it/s, epoch=8/20, avg_epoch_loss=3.97]\n",
      " 26%|██▌       | 13/50 [00:11<00:33,  1.10it/s, epoch=9/20, avg_epoch_loss=3.96]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-467aa4e167fd>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GluonTS!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mGluonTS_mean_yhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGluonTS_median_yhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGluonTS_forecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlounTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fbprophet!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfbp_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfbp_yhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfbp_yhat_upper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfbp_yhat_lower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFbprophet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-2ec9cea55c87>\u001b[0m in \u001b[0;36mGlounTS\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#estimator = DeepAREstimator(freq=\"5min\",input_size = 43, prediction_length=forecast_size, trainer=Trainer(epochs=20))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepAREstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"5min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforecast_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mListDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"target\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"2015-03-08 23:22:53\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"5min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mGluonTS_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ts_env/lib/python3.7/site-packages/gluonts/model/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data, validation_data, num_workers, num_prefetch, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m     ) -> Predictor:\n\u001b[1;32m    251\u001b[0m         return self.train_model(\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_prefetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         ).predictor\n",
      "\u001b[0;32m~/.conda/envs/ts_env/lib/python3.7/site-packages/gluonts/model/estimator.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, training_data, validation_data, num_workers, num_prefetch, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_hybrid_forward_input_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mtrain_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mvalidation_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         )\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ts_env/lib/python3.7/site-packages/gluonts/trainer/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, net, input_names, train_iter, validation_iter)\u001b[0m\n\u001b[1;32m    301\u001b[0m                     )\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m                     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_validation_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                         epoch_loss = loop(\n",
      "\u001b[0;32m~/.conda/envs/ts_env/lib/python3.7/site-packages/gluonts/trainer/_base.py\u001b[0m in \u001b[0;36mloop\u001b[0;34m(epoch_no, batch_iter, is_training)\u001b[0m\n\u001b[1;32m    251\u001b[0m                                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                             \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                             \u001b[0mlv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ts_env/lib/python3.7/site-packages/mxnet/metric.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, _, preds)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1687\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_metric\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_sum_metric\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ts_env/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2552\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ts_env/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2533\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2535\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   2536\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100%|██████████| 50/50 [01:30<00:00,  1.81s/it, epoch=2/20, avg_epoch_loss=4.14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_env",
   "language": "python",
   "name": "ts_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
